{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- Mess with classifier parameters (once working)\n",
    "- test classifier for 2 validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import exploringShipLogbooks.wordCount as wc\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from exploringShipLogbooks.basic_utils import clean_data\n",
    "from exploringShipLogbooks.basic_utils import encode_data_df\n",
    "from exploringShipLogbooks.basic_utils import extract_logbook_data\n",
    "from exploringShipLogbooks.basic_utils import isolate_columns\n",
    "from exploringShipLogbooks.basic_utils import isolate_training_data\n",
    "\n",
    "from exploringShipLogbooks.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load and clean data\n",
    "### Load CLIWOC ship logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3006: DtypeWarning: Columns (5,6,7,8,11,13,18,19,23,24,25,26,28,29,30,34,35,38,43,44,46,73,77,81,82,84,85,87,88,94,96,97,98,99,111,114,116,119,120,122,124,125,127,129,131,133,135,137,140) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "# extract data from zip file\n",
    "cliwoc_data = extract_logbook_data('CLIWOC15.csv')\n",
    "#cliwoc_data = cliwoc_data.loc[50000:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoding = preprocessing.LabelEncoder().fit(cliwoc_data['LogbookIdent']).classes_\n",
    "cliwoc_data['LogbookIdent'] = preprocessing.LabelEncoder().fit_transform(cliwoc_data['LogbookIdent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find definite slave data in CLIWOC data set\n",
    "- These logs will be used to test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  464  logs that mention slaves\n"
     ]
    }
   ],
   "source": [
    "# extract logs that mention slaves\n",
    "slave_mask = wc.count_key_words(cliwoc_data, text_columns, slave_words)\n",
    "print('Found ', len(slave_mask[slave_mask==True]), ' logs that mention slaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean CLIWOC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  4105  logs that are non-slave ships\n"
     ]
    }
   ],
   "source": [
    "# find indices of ship names that are \"non-slave\" ships before dropping ship name column\n",
    "non_slave_log_locations = isolate_training_data(cliwoc_data, {'ShipName': non_slave_ships})\n",
    "print('Found ', len(non_slave_log_locations[non_slave_log_locations==True]), ' logs that are non-slave ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliwoc_data['slave_logs'] = np.zeros(len(cliwoc_data))\n",
    "slave_log_locations = cliwoc_data['LogbookIdent'].isin(list(cliwoc_data['LogbookIdent']\n",
    "                                                            [slave_mask].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cliwoc_data (unclassified) = 0\n",
    "- cliwoc_data (no slaves)    = 1\n",
    "- cliwoc_data (slaves)       = 2\n",
    "- slave_data                 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliwoc_data.loc[non_slave_log_locations,'slave_logs'] = 1\n",
    "cliwoc_data.loc[slave_log_locations,'slave_logs'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cliwoc_data = cliwoc_data.sort_values('LogbookIdent', ascending=True)\n",
    "cliwoc_data = cliwoc_data.drop_duplicates('LogbookIdent')\n",
    "cliwoc_data = cliwoc_data.set_index('LogbookIdent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    264586\n",
       "2     11894\n",
       "1      3800\n",
       "Name: slave_logs, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cliwoc_data['slave_logs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove undesired columns\n",
    "cliwoc_data = isolate_columns(cliwoc_data, desired_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Slave Voyages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = './exploringShipLogbooks/data/tastdb-exp-2010'\n",
    "slave_voyage_logs = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year_ind = ~(slave_voyage_logs['yeardep'].isnull())\n",
    "slave_voyage_logs = slave_voyage_logs[year_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliwoc_ind = (slave_voyage_logs['yeardep']>cliwoc_data['Year'].min()) & (slave_voyage_logs['yeardep']<cliwoc_data['Year'].max())\n",
    "slave_voyage_logs = slave_voyage_logs[cliwoc_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Slave voyages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slave_voyage_desired_cols = list(slave_voyage_conversions.keys())\n",
    "slave_voyage_logs = isolate_columns(slave_voyage_logs, slave_voyage_desired_cols)\n",
    "\n",
    "slave_voyage_logs.rename(columns=slave_voyage_conversions, inplace=True)\n",
    "#slave_voyage_logs.columns = ['Nationality', 'ShipType', 'VoyageFrom', 'VoyageTo', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>ShipType</th>\n",
       "      <th>VoyageFrom</th>\n",
       "      <th>VoyageTo</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>Bergantim</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Bergantim</td>\n",
       "      <td>Bahia, port unspecified</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Bergantim</td>\n",
       "      <td>Bahia, port unspecified</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Bergantim</td>\n",
       "      <td>Bahia, port unspecified</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Galera</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nationality   ShipType               VoyageFrom  VoyageTo  Year\n",
       "1    Portugal  Bergantim           Rio de Janeiro  Alicante  1816\n",
       "2       Spain  Bergantim  Bahia, port unspecified  Alicante  1816\n",
       "3       Spain  Bergantim  Bahia, port unspecified  Alicante  1816\n",
       "4       Spain  Bergantim  Bahia, port unspecified  Alicante  1816\n",
       "5       Spain     Galera                 Alicante  Alicante  1817"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slave_voyage_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slave_voyage_logs['slave_logs'] = 3\n",
    "slave_voyage_indices = range(len(slave_voyage_logs)) + (cliwoc_data.tail(1).index[0]+1)\n",
    "slave_voyage_logs = slave_voyage_logs.set_index(slave_voyage_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VoyageFrom</th>\n",
       "      <th>VoyageTo</th>\n",
       "      <th>ShipType</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Year</th>\n",
       "      <th>slave_logs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223949</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223950</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223951</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223944</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224144</th>\n",
       "      <td>Curacao</td>\n",
       "      <td>Nederland</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VoyageFrom   VoyageTo ShipType Nationality  Year  slave_logs\n",
       "223949   Suriname  Amsterdam   Fregat       Dutch  1761           0\n",
       "223950   Suriname  Amsterdam   Fregat       Dutch  1761           0\n",
       "223951   Suriname  Amsterdam   Fregat       Dutch  1761           0\n",
       "223944   Suriname  Amsterdam   Fregat       Dutch  1761           0\n",
       "224144    Curacao  Nederland   Fregat       Dutch  1763           0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cliwoc_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>ShipType</th>\n",
       "      <th>VoyageFrom</th>\n",
       "      <th>VoyageTo</th>\n",
       "      <th>Year</th>\n",
       "      <th>slave_logs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224145</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>Bergantim</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1816</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224146</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Bergantim</td>\n",
       "      <td>Bahia, port unspecified</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1816</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224147</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Bergantim</td>\n",
       "      <td>Bahia, port unspecified</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1816</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224148</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Bergantim</td>\n",
       "      <td>Bahia, port unspecified</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1816</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224149</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Galera</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>1817</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nationality   ShipType               VoyageFrom  VoyageTo  Year  \\\n",
       "224145    Portugal  Bergantim           Rio de Janeiro  Alicante  1816   \n",
       "224146       Spain  Bergantim  Bahia, port unspecified  Alicante  1816   \n",
       "224147       Spain  Bergantim  Bahia, port unspecified  Alicante  1816   \n",
       "224148       Spain  Bergantim  Bahia, port unspecified  Alicante  1816   \n",
       "224149       Spain     Galera                 Alicante  Alicante  1817   \n",
       "\n",
       "        slave_logs  \n",
       "224145           3  \n",
       "224146           3  \n",
       "224147           3  \n",
       "224148           3  \n",
       "224149           3  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slave_voyage_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([cliwoc_data, slave_voyage_logs])\n",
    "#all_data = cliwoc_data.append(slave_voyage_logs)\n",
    "all_data = clean_data(all_data)\n",
    "\n",
    "# cleanup (my computer won't run the code without this :( )\n",
    "del cliwoc_data, slave_voyage_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of fuzzywuzzy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " df = pd.DataFrame( {'id':[1, 2, 3, 4, 5, 6], 'name':['dog', 'cat', 'mad cat', 'good dog', 'bad dog', 'chicken']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(name):\n",
    "    matches = df.apply(lambda row: (fuzz.partial_ratio(row['name'], name) >= 85), axis=1)\n",
    "    return [i for i, x in enumerate(matches) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 3, 4]\n",
       "1       [1, 2]\n",
       "2       [1, 2]\n",
       "3       [0, 3]\n",
       "4       [0, 4]\n",
       "5          [5]\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda row: func(row['name']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try fuzzywuzzy on subset of one of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(name, column_name):\n",
    "    matches = all_data[0:10].apply(lambda row: (fuzz.partial_ratio(row[column_name], name) >= 85), axis=1)\n",
    "    return [i for i, x in enumerate(matches) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "(\"name 'func' is not defined\", 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c8bdbdd88c7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcolumn_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Nationality'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   3970\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3971\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3972\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3973\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3974\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4063\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4064\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4065\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4066\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-c8bdbdd88c7f>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcolumn_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Nationality'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: (\"name 'func' is not defined\", 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "column_name = 'Nationality'\n",
    "all_data[0:10].apply(lambda row: func(row[column_name], column_name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data\n",
    "- Must encode data before separating, otherwise values that do not occur in a subset will be encoded differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = encode_data_df(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove nan columns from encoding (currently there are no empty cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['no_data'] = all_data['nan'].apply(lambda x: x.any(), axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = all_data.drop('nan', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american</th>\n",
       "      <th>argentina</th>\n",
       "      <th>brazil</th>\n",
       "      <th>british</th>\n",
       "      <th>danish</th>\n",
       "      <th>denmark</th>\n",
       "      <th>dutch</th>\n",
       "      <th>france</th>\n",
       "      <th>french</th>\n",
       "      <th>great britain</th>\n",
       "      <th>...</th>\n",
       "      <th>ysla de santa cathalina</th>\n",
       "      <th>ysla de santa cathalinaysla de santa cathalina</th>\n",
       "      <th>zeeland</th>\n",
       "      <th>ziam</th>\n",
       "      <th>zierikzee</th>\n",
       "      <th>zuid afrika</th>\n",
       "      <th>zuiden</th>\n",
       "      <th>Year</th>\n",
       "      <th>slave_logs</th>\n",
       "      <th>no_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1785</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   american  argentina  brazil  british  danish  denmark  dutch  france  \\\n",
       "0         0          0       0        0       0        0      1       0   \n",
       "1         0          0       0        0       0        0      1       0   \n",
       "2         0          0       0        0       0        0      1       0   \n",
       "3         0          0       0        0       0        0      1       0   \n",
       "4         0          0       0        0       0        0      1       0   \n",
       "\n",
       "   french  great britain   ...     ysla de santa cathalina  \\\n",
       "0       0              0   ...                           0   \n",
       "1       0              0   ...                           0   \n",
       "2       0              0   ...                           0   \n",
       "3       0              0   ...                           0   \n",
       "4       0              0   ...                           0   \n",
       "\n",
       "   ysla de santa cathalinaysla de santa cathalina  zeeland  ziam  zierikzee  \\\n",
       "0                                               0        0     0          0   \n",
       "1                                               0        0     0          0   \n",
       "2                                               0        0     0          0   \n",
       "3                                               0        0     0          0   \n",
       "4                                               0        0     0          0   \n",
       "\n",
       "   zuid afrika  zuiden  Year  slave_logs  no_data  \n",
       "0            0       0  1785           0        1  \n",
       "1            0       0  1786           0        1  \n",
       "2            0       0  1786           0        1  \n",
       "3            0       0  1786           0        1  \n",
       "4            0       0  1786           0        1  \n",
       "\n",
       "[5 rows x 2366 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract training data, and create list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unclassified_logs = all_data[all_data['slave_logs']==0]\n",
    "unclassified_logs = unclassified_logs.drop('slave_logs', axis=1)\n",
    "\n",
    "validation_set_1 = all_data[all_data['slave_logs']==2]\n",
    "validation_set_1 = validation_set_1.drop('slave_logs', axis=1)\n",
    "\n",
    "# reserve first 20% of slave_voyage_logs as validation set\n",
    "validation_set_2_indices = range(slave_voyage_indices.min(),\n",
    "                                 slave_voyage_indices.min() + round(len(slave_voyage_indices)*.2))\n",
    "validation_set_2 = all_data.iloc[validation_set_2_indices]\n",
    "validation_set_2 = validation_set_2.drop('slave_logs', axis=1)\n",
    "\n",
    "training_logs_pos = all_data.drop(validation_set_2_indices)\n",
    "training_logs_pos = training_logs_pos[training_logs_pos['slave_logs']==3]\n",
    "training_logs_pos = training_logs_pos.drop('slave_logs', axis=1)\n",
    "\n",
    "# note! This relies on cliwoc data being first in all_data\n",
    "# could make more robust later\n",
    "# TODO: check that this works!! should have some in first 1000?\n",
    "training_logs_neg = all_data[all_data['slave_logs']==1]\n",
    "training_logs_neg = training_logs_neg.drop('slave_logs', axis=1)\n",
    "\n",
    "# cleanup\n",
    "#del all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- left this code so we can check if there are any null values in each \n",
    "  dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def finding_null_values(df):\n",
    "    return df.isnull().sum()[df.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create list of classes for training data (0 is for non-slave, 1 is for slave)\n",
    "# index matches training_data\n",
    "classes = np.zeros(len(training_logs_neg))\n",
    "#classes = np.append(classes, np.ones(len(training_logs_pos)))\n",
    "classes = np.append(classes, np.ones(round(len(training_logs_pos)*.2)))\n",
    "\n",
    "# joint training data\n",
    "training_data = pd.concat([training_logs_neg, training_logs_pos[:round(len(training_logs_pos)*.2)]], ignore_index = True)\n",
    "\n",
    "# convert to numpy array\n",
    "training_data = training_data.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fit training data to classifier\n",
    "- **note!** first column of numpy array is index! do not include in classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5263, 1218)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB(alpha = 1.0, class_prior = None, fit_prior = True)\n",
    "classifier.fit(training_data[::,1::], classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test classifier\n",
    "- check if slave logs from cliwoc data were classified correctly (want mostly classified as 1)\n",
    "- compare first column with slave_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_test(classifier, validation_set, expected_class):\n",
    "    \"\"\"\n",
    "    input classifer object, validation set (data frame), and expected class \n",
    "    of validation set (i.e. 1 or 0). Prints successful classification rate.\n",
    "    \"\"\"\n",
    "    validation_set = validation_set.as_matrix()\n",
    "    predictions = classifier.predict(validation_set[::,1::])\n",
    "    \n",
    "    counts = collections.Counter(predictions)\n",
    "    percent_correct = (counts[expected_class]/(len(predictions))* 100)\n",
    "                       \n",
    "    print('Validation set was classified as', expected_class,\n",
    "          round(percent_correct,2), '% of the time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing validation data from slave logs data set\n",
      "Validation set was classified as 1 100.0 % of the time\n",
      "Testing validation data from cliwoc data set:\n",
      "Validation set was classified as 1 100.0 % of the time\n"
     ]
    }
   ],
   "source": [
    "print('Testing validation data from slave logs data set')\n",
    "validation_test(classifier, validation_set_2, 1)\n",
    "\n",
    "print('Testing validation data from cliwoc data set:')\n",
    "validation_test(classifier, validation_set_1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set was classified as 1 100.0 % of the time\n"
     ]
    }
   ],
   "source": [
    "validation_test(classifier, unclassified_logs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
